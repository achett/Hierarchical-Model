{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achett/Hierarchical-Model/blob/main/Revenue_FY23_Blind_Test_Enhancements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gkwj_W9Hql7u"
      },
      "outputs": [],
      "source": [
        "# !pip install hierarchicalforecast\n",
        "# !pip install statsforecast\n",
        "# !pip install datasetsforecast\n",
        "# !pip install nixtlats>=0.1.0\n",
        "# !pip install darts\n",
        "# !pip install mlforecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VfHIyAUyrdyY"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# PACKAGES\n",
        "########################\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import openpyxl\n",
        "from datetime import datetime\n",
        "from functools import reduce\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# from statsforecast.core import StatsForecast\n",
        "# from statsforecast.models import AutoARIMA, Naive, AutoETS, AutoCES, AutoTheta\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# from hierarchicalforecast.core import HierarchicalReconciliation\n",
        "# from hierarchicalforecast.evaluation import HierarchicalEvaluation\n",
        "# from hierarchicalforecast.methods import BottomUp, TopDown, MiddleOut, MinTrace, OptimalCombination, ERM, PERMBU, Bootstrap, Normality\n",
        "# from hierarchicalforecast.utils import aggregate\n",
        "# from nixtlats import TimeGPT\n",
        "# os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
        "\n",
        "\n",
        "# from darts import TimeSeries, concatenate\n",
        "# from darts.models import RegressionModel, LightGBMModel, ExponentialSmoothing, StatsForecastAutoETS, StatsForecastAutoARIMA, KalmanForecaster\n",
        "# from darts.dataprocessing.transformers import Scaler\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from darts.metrics import mae, rmse, mape, mql, mse, ope\n",
        "# from darts.utils.likelihood_models import QuantileRegression\n",
        "\n",
        "pd.options.display.float_format = '{:,.2f}'.format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-4tIiYy6rjtR"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# PARAMS\n",
        "##############\n",
        "fct_periods = 15\n",
        "fct_st_date = '2023-04-01'\n",
        "fct_end_date = '2024-03-01'\n",
        "\n",
        "# Create hierarchical structure and constraints\n",
        "hierarchy_levels = [['TopLv'],\n",
        "                    ['TopLv', 'ProductLv'],\n",
        "                    ['TopLv', 'ProductLv', 'Lv1'],\n",
        "                    ['TopLv', 'ProductLv', 'Lv1', 'Lv2'],\n",
        "                    ['TopLv', 'ProductLv', 'Lv1', 'Lv2', 'Lv3'],\n",
        "                    ['TopLv', 'ProductLv', 'Lv1', 'Lv2', 'Lv3', 'Lv4'],\n",
        "                    ['TopLv', 'ProductLv', 'Lv1', 'Lv2', 'Lv3', 'Lv4', 'Lv5']]\n",
        "\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/regional_hierarchy.xlsx'\n",
        "sheet_name = 'regional_hierarchy v2'\n",
        "r_hier = pd.read_excel(inputFile, sheet_name=sheet_name)\n",
        "\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/model_selection.xlsx'\n",
        "model_selection = pd.read_excel(inputFile)\n",
        "\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/Product Naming Convention.xlsx'\n",
        "product_naming_convention = pd.read_excel(inputFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0yaRJqN3rou6"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# FUNCTIONS\n",
        "##############\n",
        "def prepare_data(data, r_hier):\n",
        "\n",
        "    # Merge hierarchy\n",
        "    data = data.merge(r_hier, how='inner', left_on='cost_object', right_on='Lv5')\n",
        "\n",
        "    # Transform date and y\n",
        "    data['ds'] = pd.to_datetime(data['ds'])\n",
        "    data['y'] = data['y'].astype(float)\n",
        "\n",
        "    # Address NA values\n",
        "    data['y'] = data['y'].fillna(0)\n",
        "    data['TopLv'] = data['TopLv'].fillna('')\n",
        "    data['Lv1'] = data['Lv1'].fillna('')\n",
        "    data['Lv2'] = data['Lv2'].fillna('')\n",
        "    data['Lv3'] = data['Lv3'].fillna('')\n",
        "    data['Lv4'] = data['Lv4'].fillna('')\n",
        "    data['Lv5'] = data['Lv5'].fillna('')\n",
        "    data['product'] = data['product'].fillna('')\n",
        "\n",
        "    # Create hierarchical dataframe\n",
        "    data.rename(columns={'product': 'ProductLv'}, inplace=True)\n",
        "    data = data[['TopLv', 'ProductLv', 'Lv1', 'Lv2', 'Lv3', 'Lv4', 'Lv5', 'ds', 'y']]\n",
        "\n",
        "    # Replace '/' with '_' in the four columns\n",
        "    data['TopLv'] = data['TopLv'].str.replace('/', '_')\n",
        "    data['ProductLv'] = data['ProductLv'].str.replace('/', '_')\n",
        "    data['Lv1'] = data['Lv1'].str.replace('/', '_')\n",
        "    data['Lv2'] = data['Lv2'].str.replace('/', '_')\n",
        "    data['Lv3'] = data['Lv3'].str.replace('/', '_')\n",
        "    data['Lv4'] = data['Lv4'].str.replace('/', '_')\n",
        "    data['Lv5'] = data['Lv5'].str.replace('/', '_')\n",
        "\n",
        "    data['unique_id'] = data['TopLv'] + '/' + data['ProductLv'] + '/' + data['Lv1'] + '/' + data['Lv2'] + '/' + data['Lv3'] + '/' + data['Lv4'] + '/' + data['Lv5']\n",
        "\n",
        "    # Assuming df is your existing DataFrame\n",
        "    grouping_columns = ['TopLv', 'ProductLv', 'Lv1', 'Lv2', 'Lv3', 'Lv4', 'Lv5', 'ds', 'unique_id']  # All columns except 'y'\n",
        "\n",
        "    # Group by specified columns and sum 'y'\n",
        "    data = data.groupby(grouping_columns)['y'].sum().reset_index()\n",
        "\n",
        "    return data\n",
        "\n",
        "def prepare_feature(data, r_hier, volume_act2, feature_name):\n",
        "\n",
        "    # Select and rename columns\n",
        "    data = data[['cost_object', 'product', 'ds', feature_name]].rename(columns={feature_name: 'y'})\n",
        "\n",
        "    # Apply any additional preparation (assuming prepare_data is a function you have defined)\n",
        "    data = prepare_data(data, r_hier)\n",
        "\n",
        "    # Rename the columns back\n",
        "    data = data.rename(columns={'y': feature_name})\n",
        "\n",
        "    # Merge with the volume_act2 dataframe\n",
        "    merged_df = data.merge(volume_act2[['unique_id', 'ds']], how='right', on=['unique_id', 'ds'])\n",
        "\n",
        "    return merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oSsQWynbryxz"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# DATA LOAD\n",
        "##############\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/budgetFY23.csv'\n",
        "budget = pd.read_csv(inputFile)\n",
        "# budget = budget[budget['category']=='EQUIV_UNIT - Equivalent Units']\n",
        "budget = budget[budget['category']=='UC110000 - Total Revenue']\n",
        "budget.rename(columns={'country': 'cost_object'}, inplace=True)\n",
        "budget = prepare_data(budget, r_hier)\n",
        "\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/revenue_output.csv'\n",
        "volume_act = pd.read_csv(inputFile)\n",
        "volume_act.rename(columns={'value': 'y'}, inplace=True)\n",
        "volume_act = prepare_data(volume_act, r_hier)\n",
        "\n",
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/SGA Prediction/data/sga_output.csv'\n",
        "sga = pd.read_csv(inputFile)\n",
        "\n",
        "sga1 = prepare_feature(sga, r_hier, volume_act, 'AP')\n",
        "sga2 = prepare_feature(sga, r_hier, volume_act, 'Field_Sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V9F_DXanr9w8"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# IDENTIFY UNIVERSE\n",
        "########################\n",
        "tested_ts = set(budget['unique_id'].unique()).intersection(volume_act['unique_id'].unique())\n",
        "\n",
        "# Find unique IDs present in budget_h but not in rev\n",
        "unique_ids_in_budget_not_in_rev = set(budget['unique_id'].unique()).difference(volume_act['unique_id'].unique())\n",
        "\n",
        "# Find unique IDs present in rev but not in budget_h\n",
        "unique_ids_in_rev_not_in_budget = set(volume_act['unique_id'].unique()).difference(budget['unique_id'].unique())\n",
        "\n",
        "# Filter volume\n",
        "volume_act = volume_act[volume_act['unique_id'].isin(tested_ts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pt5jn6s4sDly"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# SEGMENT TIME SERIES\n",
        "########################\n",
        "new_products = ['ENFORTUMAB - Enforumab Vedotin', 'ROXADUSTNT - Roxadustant']\n",
        "loe_products = ['REGADENOSN - Regadenoson']\n",
        "div_products = ['MICAFUNGIN - Micafungin Sodium']\n",
        "\n",
        "new_ids = volume_act[volume_act['ProductLv'].isin(new_products)]['unique_id'].unique().tolist()\n",
        "loe_ids = volume_act[volume_act['ProductLv'].isin(loe_products)]['unique_id'].unique().tolist()\n",
        "divested_ids = volume_act[volume_act['ProductLv'].isin(div_products)]['unique_id'].unique().tolist()\n",
        "\n",
        "# IDs with A&P and Field Sales Spend\n",
        "grouped1 = sga1.groupby('unique_id')[['AP']].sum()\n",
        "grouped2 = sga2.groupby('unique_id')[['Field_Sales']].sum()\n",
        "spend_ids = set(grouped1[(grouped1['AP'] > 0)].index.tolist() + grouped2[(grouped2['Field_Sales'] > 0)].index.tolist())\n",
        "spend_ids = spend_ids.difference(new_ids + loe_ids + divested_ids)\n",
        "\n",
        "# IDs with no spend\n",
        "non_spend_ids = volume_act[~volume_act['unique_id'].isin(spend_ids)]['unique_id'].unique()\n",
        "\n",
        "# Model Selection\n",
        "arima_regions = model_selection[model_selection['model']=='ARIMA']['Lv3'].unique()\n",
        "ets_regions = model_selection[model_selection['model']=='ETS']['Lv3'].unique()\n",
        "# arima_ids = volume_act[(volume_act['level3'].isin(arima_regions)) & (~volume_act['unique_id'].isin(spend_ids))]['unique_id'].unique().tolist()\n",
        "# ets_ids = volume_act[(volume_act['level3'].isin(ets_regions)) & (~volume_act['unique_id'].isin(spend_ids))]['unique_id'].unique().tolist()\n",
        "\n",
        "arima_ids = volume_act[(volume_act['Lv3'].isin(arima_regions))]['unique_id'].unique().tolist()\n",
        "ets_ids = volume_act[(volume_act['Lv3'].isin(ets_regions))]['unique_id'].unique().tolist()\n",
        "\n",
        "# Solifenacin _ Tamsulosin\n",
        "solif_tams_ids = volume_act[volume_act['ProductLv'].isin(['SOLIF_TAMS - Solifenacin _ Tamsulosin', 'TAMSULOSIN - Tamsulosin HCl', 'TAMSUL_TAB - Tamsulosin tab'])]['unique_id'].unique().tolist()\n",
        "arima_ids = set(arima_ids+solif_tams_ids)\n",
        "ets_ids = [id for id in ets_ids if id not in solif_tams_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8KHNvrJBsIL0"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# DATA CONVERSION\n",
        "########################\n",
        "set2zero_list=['Global/TAMSULOSIN - Tamsulosin HCl/D_GCN - Greater China/D_CN_TOTAL - China Total/D_CN_TOTAL - China Total/D_CN_TOTAL - China Total/D_CN_TOTAL - China Total',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BENELUX - Benelux/D_E_BELGIUM - Belgium/D_E_BELGIUM - Belgium',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BBMCI - BBMCI group/D_E_BALKANS - Balkans/D_E_BOS_HER - Bosnia-Herz.',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BBMCI - BBMCI group/D_E_BALKANS - Balkans/D_E_BOS_HER - Bosnia-Herz.',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_ADRCS_PT - Adriatics & Portugal/D_E_ADRCS - Adriatic Adriatics/D_E_CROATIA - Croatia',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_ADRCS_PT - Adriatics & Portugal/D_E_ADRCS - Adriatic Adriatics/D_E_CROATIA - Croatia',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_CZSK - Czech + Slovakia/D_E_CZECH - Czech',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_FRANCE - France/D_E_FRANCE - France/D_E_FRANCE - France/D_E_FRANCE - France',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_FRANCE - France/D_E_FRANCE - France/D_E_FRANCE - France/D_E_FRANCE - France',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_GB - Great Britain/D_E_GB - Great Britain/D_E_GB - Great Britain/D_E_GB - Great Britain',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_HUBGROGR - HBRG/D_E_HUBGRO - Hungary  Bulgaria & Romania/D_E_HU - Hungary',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_IE - Ireland/D_E_IE - Ireland/D_E_IE - Ireland',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_IT - Italy/D_E_IT - Italy/D_E_IT - Italy/D_E_IT - Italy',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BBMCI - BBMCI group/D_E_MTCYIS - Malta  Cyprus & Iceland/D_E_MALTA - Malta',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_NORDIC - Nordic/D_E_NORWAY - Norway/D_E_NORWAY - Norway',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_PO - Poland/D_E_PO - Poland',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_PO - Poland/D_E_PO - Poland',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_CZSK - Czech + Slovakia/D_E_SLOVAKIA - Slovakia',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_SPAIN - Spain/D_E_SPAIN - Spain/D_E_SPAIN - Spain/D_E_SPAIN - Spain',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_UA - Ukraine/D_E_UA - Ukraine',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_UA - Ukraine/D_E_UA - Ukraine',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_GCN - Greater China/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_GCN - Greater China/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total/D_HK_TOTAL - Hong Kong Total',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_BEL - Belarus/D_I_CIS_BEL - Belarus/D_I_CIS_BEL - Belarus',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_BEL - Belarus/D_I_CIS_BEL - Belarus/D_I_CIS_BEL - Belarus',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_MEA_OB - MEA Own Business/D_I_EGYPT - Egypt/D_I_EGYPT - Egypt/D_I_EGYPT - Egypt',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_APAC_CORE - APAC CORE/D_I_INDONESIA - Indonesia/D_I_INDONESIA - Indonesia/D_I_INDONESIA - Indonesia',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_MEA_DB - Distributor Business/D_I_IRAQ - Iraq/D_I_IRAQ - Iraq/D_I_IRAQ - Iraq',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_MEA_DB - Distributor Business/D_I_JORDAN - Jordan/D_I_JORDAN - Jordan/D_I_JORDAN - Jordan',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_LATAM - Domestic - LatAM/D_I_LATAM_REST - Domestic Rest of Latam/D_I_LATAM_REST_OTH - Domestic Rest of Latam Others/D_I_LATAM_REST_OTH - Domestic Rest of Latam Others',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_MEA_DB - Distributor Business/D_I_LEBANON - Lebanon/D_I_LEBANON - Lebanon/D_I_LEBANON - Lebanon',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_APAC_CORE - APAC CORE/D_I_PHILIPPINES - Philippines/D_I_PHILIPPINES - Philippines/D_I_PHILIPPINES - Philippines',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_MEA_OB - MEA Own Business/D_I_SAFRICA - South Africa/D_I_SAFRICA - South Africa/D_I_SAFRICA - South Africa',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_APAC_CORE - APAC CORE/D_I_SINMAL - SINMAL/D_I_SINGAPORE - SINGAPORE/D_I_SINGAPORE - SINGAPORE',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_I_INTL - International Markets/D_I_TURKEY - Turkey/D_I_TURKEY - Turkey/D_I_TURKEY - Turkey/D_I_TURKEY - Turkey',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_I_INTL - International Markets/D_I_APAC_CORE - APAC CORE/D_I_VIETNAM - Vietnam/D_I_VIETNAM - Vietnam/D_I_VIETNAM - Vietnam',\n",
        "       'Global/TAMSULOSIN - Tamsulosin HCl/D_GCN - Greater China/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total',\n",
        "       'Global/TAMSUL_TAB - Tamsulosin tab/D_GCN - Greater China/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total/D_TW_TOTAL - Taiwan Total',\n",
        "      'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_E_ESTMKT - Established Markets/D_E_IT - Italy/D_E_IT - Italy/D_E_IT - Italy/D_E_IT - Italy',\n",
        "       'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BENELUX - Benelux/D_E_NETHLND - Netherlands/D_E_NETHLND - Netherlands',\n",
        "       'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_CZSK - Czech + Slovakia/D_E_SLOVAKIA - Slovakia',\n",
        "       'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_PCSU - PCSU/D_E_UA - Ukraine/D_E_UA - Ukraine',\n",
        "       'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_I_INTL - International Markets/D_I_LATAM - Domestic - LatAM/D_I_LATAM_DB - Domestic Latam Distributor Business/D_I_AR - Domestic Argentina/D_I_AR - Domestic Argentina',\n",
        "       'Global/SOLIF_TAMS - Solifenacin _ Tamsulosin/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan/D_I_CIS_KAZ - Kazakhstan']\n",
        "\n",
        "volume_act.loc[(volume_act['unique_id'].isin(set2zero_list)) & (volume_act['ds'] < '2022-04-01'), 'y'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ptpidyQrDNK"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# SAMPLE\n",
        "########################\n",
        "# ts2fix = ['Global/ROMOSOZUMA - ROMOSOZUMA/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/JP10 - Astellas Pharma Inc', 'Global/MIRABEGRON - Mirabegron/D_E_ESTMKT - Established Markets/D_E_CA - Canada/D_E_CA - Canada/D_E_CA - Canada/D_E_CA - Canada',\n",
        "#           'Global/MIRABEGRON - Mirabegron/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/US10 - Astellas Pharma US, Inc.', 'Global/ENZA - Enzalutamide/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/US10 - Astellas Pharma US, Inc.',\n",
        "#           'Global/ENZA - Enzalutamide/D_E_ESTMKT - Established Markets/D_E_DE - Germany/D_E_DE - Germany/D_E_DE - Germany/D_E_DE - Germany', 'Global/ENZA - Enzalutamide/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/JP10 - Astellas Pharma Inc',\n",
        "#           'Global/ENZA - Enzalutamide/D_I_INTL - International Markets/D_I_RBK_CORE - RBK Core/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia/D_I_CIS_RUS - Russia']\n",
        "\n",
        "# volume_act = volume_act[volume_act['unique_id'].isin(ts2fix)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K5zwG5M-sMfy"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# RUN ETS & ARIMA\n",
        "########################\n",
        "# def convert_fct2df(forecasts):\n",
        "#     forecast_dfs = []\n",
        "#     for unique_id, forecast_ts in forecasts.items():\n",
        "#         df = TimeSeries.quantiles_df(forecast_ts, quantiles=[0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995])\n",
        "#         df['unique_id'] = unique_id\n",
        "#         df = df.reset_index()\n",
        "#         df = df.rename(columns={'y_0.5': 'y'})\n",
        "#         forecast_dfs.append(df)\n",
        "\n",
        "#     # Concatenate all forecast DataFrames into a single DataFrame\n",
        "#     all_forecasts_df = pd.concat(forecast_dfs, axis=0)\n",
        "\n",
        "#     # Reorder and rename columns as needed\n",
        "#     columns = ['unique_id'] + [col for col in all_forecasts_df.columns if col != 'unique_id']\n",
        "#     all_forecasts_df = all_forecasts_df[columns]\n",
        "\n",
        "#     all_forecasts_df.columns.name = None\n",
        "\n",
        "#     return all_forecasts_df\n",
        "\n",
        "# def generate_time_series_dict(data, fct_periods, filter_data):\n",
        "#     # Split train/test sets\n",
        "#     test = data.groupby('unique_id').tail(fct_periods)\n",
        "#     train = data.drop(test.index)\n",
        "\n",
        "#     # Prepare time series dataframes\n",
        "#     time_series_dfs = {uid: group for uid, group in train.groupby('unique_id')}\n",
        "#     time_series_dict = {}\n",
        "\n",
        "#     if filter_data:\n",
        "#         # Filter out time series with insufficient non-zero data points\n",
        "#         filtered_time_series_dfs = {}\n",
        "#         for uid, group in time_series_dfs.items():\n",
        "#             non_zero_index = group['y'].ne(0).idxmax()\n",
        "#             start_index = max(0, non_zero_index - (13 - 1))\n",
        "#             filtered_df = group.loc[non_zero_index:] if group.loc[non_zero_index:].shape[0] >= 13 else group.loc[start_index:]\n",
        "#             if not filtered_df.empty:\n",
        "#                 filtered_time_series_dfs[uid] = filtered_df\n",
        "#         # Convert each filtered DataFrame into a Darts TimeSeries object\n",
        "\n",
        "#         time_series_dict = {uid: TimeSeries.from_dataframe(group, 'ds', 'y') for uid, group in filtered_time_series_dfs.items()}\n",
        "#     else:\n",
        "#         # Convert each original DataFrame into a Darts TimeSeries object without filtering\n",
        "#         time_series_dict = {uid: TimeSeries.from_dataframe(group, 'ds', 'y') for uid, group in time_series_dfs.items()}\n",
        "\n",
        "#     return time_series_dict\n",
        "\n",
        "# def generate_forecast(data, fct_periods, model2use, filter_data=True):\n",
        "\n",
        "#     # Use the nested function to generate the time series dictionary\n",
        "#     time_series_dict = generate_time_series_dict(data, fct_periods, filter_data)\n",
        "\n",
        "#     # Create and fit a model for each time series\n",
        "#     models = {}\n",
        "#     for uid, series in time_series_dict.items():\n",
        "#         model = get_model(model2use)\n",
        "#         model.fit(series)\n",
        "#         models[uid] = model\n",
        "\n",
        "#     # Forecasting\n",
        "#     fct_dict = {uid: model.predict(fct_periods, num_samples=1000) for uid, model in models.items()}\n",
        "\n",
        "#     # Convert forecasts into a dataframe\n",
        "#     fct_df = convert_fct2df(fct_dict)\n",
        "#     print('hi')\n",
        "#     return fct_dict, fct_df\n",
        "\n",
        "# # Function to dynamically get the model instance\n",
        "# def get_model(model_name):\n",
        "#     if model_name == 'AutoETS':\n",
        "#         return StatsForecastAutoETS()\n",
        "#     elif model_name == 'ARIMA':\n",
        "#         return StatsForecastAutoARIMA(season_length=12)\n",
        "#     elif model_name == 'KF':\n",
        "#         return KalmanForecaster(dim_x=12)\n",
        "#     else:\n",
        "#         raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "# # q = volume_act[volume_act['unique_id']=='Global/AMPHOTERCN - Amphotericin B/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/D_USCOM - US Commercial/US10 - Astellas Pharma US, Inc.']\n",
        "\n",
        "# # Check if 'ets_ids' list has values before running 'AutoETS' model\n",
        "# if ets_ids:\n",
        "#     ets_filtered_data = volume_act[volume_act['unique_id'].isin(ets_ids)]\n",
        "#     if not ets_filtered_data.empty:  # Also check if the filtered DataFrame is not empty\n",
        "#         ets_dict, ets_df = generate_forecast(ets_filtered_data, fct_periods, model2use='AutoETS', filter_data=True)\n",
        "\n",
        "# # Check if 'arima_ids' list has values before running 'ARIMA' model\n",
        "# if arima_ids:\n",
        "#     arima_filtered_data = volume_act[volume_act['unique_id'].isin(arima_ids)]\n",
        "#     if not arima_filtered_data.empty:  # Also check if the filtered DataFrame is not empty\n",
        "#         arima_dict, arima_df = generate_forecast(arima_filtered_data, fct_periods, model2use='ARIMA', filter_data=True)\n",
        "\n",
        "# # You can uncomment the following line if you want to always run 'KF' model regardless of filtering\n",
        "# # kf_fct = generate_forecast(volume_act, fct_periods, model2use='KF', filter_data=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MHrE9qdksWJf"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# XTREND - DECAY\n",
        "########################\n",
        "# import pandas as pd\n",
        "# from dateutil.relativedelta import relativedelta\n",
        "# import numpy as np\n",
        "\n",
        "# def apply_exponential_decay(df, start_date, end_date, end_value_percentage, target_unique_ids):\n",
        "\n",
        "#     # Convert 'ds' to datetime if it's not already and sort\n",
        "#     df['ds'] = pd.to_datetime(df['ds'])\n",
        "#     df = df.sort_values(by='ds')\n",
        "#     start_date = pd.to_datetime(start_date)\n",
        "#     end_date = pd.to_datetime(end_date)\n",
        "\n",
        "#     # Loop through each group (unique_id)\n",
        "#     for unique_id in target_unique_ids:\n",
        "#         group = df[df['unique_id'] == unique_id]\n",
        "\n",
        "#         # Columns to apply decay to\n",
        "#         decay_columns = [col for col in group.columns if col not in ['unique_id', 'ds']]\n",
        "\n",
        "#         # Initialize a dictionary to keep the end values for each decay column\n",
        "#         end_values = {}\n",
        "\n",
        "#         # Find start and end values and dates for each column\n",
        "#         for col in decay_columns:\n",
        "#             if start_date in group['ds'].values and end_date in group['ds'].values:\n",
        "#                 start_value = group.loc[group['ds'] == start_date, col].iloc[0]\n",
        "#                 end_value = start_value * end_value_percentage\n",
        "#                 end_values[col] = end_value  # Store the end value for this column\n",
        "\n",
        "#                 # Calculate the decay rate based on exponential decay formula\n",
        "#                 months = relativedelta(end_date, start_date).months\n",
        "#                 decay_rate = np.log(end_value / start_value) / months\n",
        "\n",
        "#                 # Apply exponential decay for dates between start_date and end_date\n",
        "#                 for date in pd.date_range(start_date, end_date):\n",
        "#                     if date in group['ds'].values:\n",
        "#                         t = relativedelta(date, start_date).months\n",
        "#                         new_value = start_value * np.exp(decay_rate * t)\n",
        "#                         df.loc[(df['unique_id'] == unique_id) & (df['ds'] == date), col] = new_value\n",
        "\n",
        "#         # Replace column values for dates after end_date with the respective end values\n",
        "#         for col, end_value in end_values.items():\n",
        "#             if end_value is not None:  # Ensure there was an end value calculated\n",
        "#                 df.loc[(df['unique_id'] == unique_id) & (df['ds'] > end_date), col] = end_value\n",
        "\n",
        "#     return df\n",
        "\n",
        "\n",
        "# # Apply exponential decay\n",
        "# # lgbm_fct.rename(columns={'LGBM': 'y'}, inplace=True)\n",
        "# ets_df.rename(columns={'ETS': 'y'}, inplace=True)\n",
        "# arima_df.rename(columns={'ARIMA': 'y'}, inplace=True)\n",
        "\n",
        "# # Micafungin\n",
        "# arima_df = apply_exponential_decay(arima_df, '2023-07-01', '2023-08-01', 0, divested_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2023-07-01', '2023-08-01', 0, divested_ids)\n",
        "\n",
        "# # Lexiscan\n",
        "# arima_df = apply_exponential_decay(arima_df, '2023-01-01', '2023-12-01', .1, loe_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2023-01-01', '2023-12-01', .1, loe_ids)\n",
        "\n",
        "# # # Tamsulosin\n",
        "# # tamsulosin_ids = volume_act[volume_act['ProductLv'].isin(['TAMSULOSIN - Tamsulosin HCl', 'TAMSUL_TAB - Tamsulosin tab'])]['unique_id'].unique()\n",
        "# # arima_df = apply_exponential_decay(arima_df, '2023-04-01', '2023-12-01', .9, tamsulosin_ids)\n",
        "# # ets_df = apply_exponential_decay(ets_df, '2023-04-01', '2023-12-01', .9, tamsulosin_ids)\n",
        "\n",
        "# # Solifinacin Tamsulosin\n",
        "# solif_tams_ids = volume_act[(volume_act['ProductLv'].isin(['SOLIF_TAMS - Solifenacin _ Tamsulosin'])) & (volume_act['Lv5'].isin(['D_E_PORTUGAL - Portugal', 'D_E_SPAIN - Spain', 'D_E_GB - Great Britain', 'D_E_BG - Bulgaria']))]['unique_id'].unique()\n",
        "# arima_df = apply_exponential_decay(arima_df, '2023-06-01', '2023-12-01', .7, solif_tams_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2023-06-01', '2023-12-01', .7, solif_tams_ids)\n",
        "\n",
        "# # Xtandi\n",
        "# xtandi_ids = volume_act[(volume_act['ProductLv'].isin(['ENZA - Enzalutamide']))]['unique_id'].unique()\n",
        "# arima_df = apply_exponential_decay(arima_df, '2027-11-01', '2028-11-01', .1, xtandi_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2027-11-01', '2028-11-01', .1, xtandi_ids)\n",
        "\n",
        "# # Mirabegron\n",
        "# mira_ids = volume_act[(volume_act['ProductLv'].isin(['MIRABEGRON - Mirabegron']))]['unique_id'].unique()\n",
        "# arima_df = apply_exponential_decay(arima_df, '2025-11-01', '2026-11-01', .1, mira_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2025-11-01', '2026-11-01', .1, mira_ids)\n",
        "\n",
        "# # Cresemba\n",
        "# cres_ids = volume_act[(volume_act['ProductLv'].isin(['ISA_SULFAT - Isavuconazonium Sulfate']))]['unique_id'].unique()\n",
        "# arima_df = apply_exponential_decay(arima_df, '2027-03-01', '2028-03-01', .1, cres_ids)\n",
        "# ets_df = apply_exponential_decay(ets_df, '2027-03-01', '2028-03-01', .1, cres_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RPynYHy0sdVV"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# CREATE ANALYTICAL TABLE\n",
        "########################\n",
        "# # Subset\n",
        "# volume_act_xsm = volume_act[['unique_id', 'ds', 'y']]\n",
        "# budget2 = budget[['unique_id', 'ds', 'y']]\n",
        "# ets_df2 = ets_df[['unique_id', 'ds', 'y']]\n",
        "# arima_df2 = arima_df[['unique_id', 'ds', 'y']]\n",
        "\n",
        "# # Assign names\n",
        "# volume_act_xsm.rename(columns={'y': 'Actuals'}, inplace=True)\n",
        "# budget2.rename(columns={'y': 'Budget'}, inplace=True)\n",
        "# ets_df2.rename(columns={'y': 'ETS'}, inplace=True)\n",
        "# arima_df2.rename(columns={'y': 'ARIMA'}, inplace=True)\n",
        "\n",
        "# # Merge actuals, budget and forecast\n",
        "# rev_at = volume_act_xsm.merge(ets_df2, on=['unique_id', 'ds'], how='left')\n",
        "# rev_at = rev_at.merge(budget2, on=['unique_id', 'ds'], how='left')\n",
        "# rev_at = rev_at.merge(arima_df2, on=['unique_id', 'ds'], how='left')\n",
        "\n",
        "# # Conditions for selection\n",
        "# conditions = [rev_at['unique_id'].isin(arima_ids),rev_at['unique_id'].isin(ets_ids)]\n",
        "# choices = [rev_at['ARIMA'],rev_at['ETS']]\n",
        "\n",
        "# # Creating the new column 'SelectedFCT' based on the conditions\n",
        "# rev_at['SelectedFCT'] = np.select(conditions, choices, default=np.nan)\n",
        "\n",
        "# # Only keep tested ts\n",
        "# rev_at = rev_at[rev_at['unique_id'].isin(tested_ts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MbuwK95l0wy1"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# CREATE DATA2PLOT\n",
        "########################\n",
        "# # Add revenue actuals\n",
        "# data2plot = rev_at.copy()\n",
        "# data2plot = data2plot[['unique_id', 'ds', 'Actuals']]\n",
        "# data2plot['ds'] = pd.to_datetime(data2plot['ds'])\n",
        "\n",
        "# # Update Actuals columns\n",
        "# data2plot['Actuals (Train)'] = data2plot['Actuals'].copy()\n",
        "# data2plot['Actuals'] = data2plot.apply(lambda row: row['Actuals'] if row['ds'] >= datetime.strptime(fct_st_date, \"%Y-%m-%d\") else None, axis=1)\n",
        "# data2plot['Actuals (Train)'] = data2plot.apply(lambda row: row['Actuals (Train)'] if row['ds'] < datetime.strptime(fct_st_date, \"%Y-%m-%d\") else None, axis=1)\n",
        "\n",
        "# # Add forecast and budget\n",
        "# data2plot = data2plot.merge(rev_at[['unique_id', 'ds', 'SelectedFCT']], how='left', on=['unique_id', 'ds'])\n",
        "# data2plot = data2plot.merge(rev_at[['unique_id', 'ds', 'Budget']], how='left', on=['unique_id', 'ds'])\n",
        "\n",
        "# data2plot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vz9D9StzYOq6"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# PLOT\n",
        "########################\n",
        "# import ipywidgets as widgets\n",
        "# from ipywidgets import interact\n",
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from IPython.display import display, HTML\n",
        "# import base64\n",
        "# from io import BytesIO\n",
        "\n",
        "# # Update the function to include filtering based on 'unique_id'\n",
        "# def plot_data(unique_id):\n",
        "#     # Define x_column and y_columns directly\n",
        "#     x_column = data2use.columns[1]\n",
        "#     y_columns = [data2use.columns[2], data2use.columns[3], data2use.columns[4], data2use.columns[5]]\n",
        "\n",
        "#     # Filter data based on selected unique_id\n",
        "#     filtered_data = data2use[data2use['unique_id'] == unique_id]\n",
        "\n",
        "#     # Set up a 1x3 grid of subplots\n",
        "#     fig, (ax1, ax4) = plt.subplots(1, 2, figsize=(25, 5), gridspec_kw={'width_ratios': [4, 1]}) # Adjust layout for table\n",
        "\n",
        "#     # Plotting multiple y-axes on the first subplot\n",
        "#     for y_column in y_columns:\n",
        "#         ax1.plot(filtered_data[x_column], filtered_data[y_column], label=y_column)\n",
        "#     ax1.set_xlabel(x_column)\n",
        "#     ax1.set_ylabel('Values')\n",
        "#     ax1.set_title(f'Revenue for {unique_id}')\n",
        "#     ax1.legend()\n",
        "\n",
        "#     # Remove axis for table\n",
        "#     ax4.axis('off')\n",
        "#     ax4.axis('tight')\n",
        "\n",
        "#     # Displaying the sum table\n",
        "#     display_data = filtered_data[[x_column] + list(y_columns)].copy()\n",
        "#     display_data = display_data[display_data['ds']>=fct_st_date]\n",
        "#     display_data['ds'] = display_data['ds'].dt.strftime('%m/%d/%Y')\n",
        "\n",
        "#     # Create a sum row\n",
        "#     sum_values = {x_column: 'Sum'}\n",
        "#     for col in list(y_columns):\n",
        "#         sum_values[col] = display_data[col].sum()\n",
        "#     sum_row = pd.DataFrame([sum_values])\n",
        "\n",
        "#     # Create a % diff row\n",
        "#     actuals_sum = sum_values['Actuals']\n",
        "#     pdiff_values = {x_column: '% Diff'}\n",
        "#     for col in list(y_columns):\n",
        "#         pdiff_values[col] = ((display_data[col].sum()-actuals_sum) / actuals_sum) * 100 if actuals_sum != 0 else None\n",
        "#         pdiff_values[col] = round(pdiff_values[col], 2)\n",
        "#     perc_diff_row = pd.DataFrame([pdiff_values])\n",
        "\n",
        "#     # Stack the sum row\n",
        "#     display_data = pd.concat([sum_row, display_data], ignore_index=True)\n",
        "\n",
        "#     # Round the values and add commas\n",
        "#     for column in y_columns:\n",
        "#         if column in display_data.columns:\n",
        "#             # Round to two decimal places\n",
        "#             display_data[column] = display_data[column].round(2)\n",
        "#             # Format with commas\n",
        "#             display_data[column] = display_data[column].apply(lambda x: f\"{x:,.2f}\")\n",
        "\n",
        "#     # Stack the % diff and remove 'Actuals Train'\n",
        "#     display_data = pd.concat([perc_diff_row, display_data], ignore_index=True)\n",
        "#     display_data = display_data.drop('Actuals (Train)', axis=1)\n",
        "\n",
        "#     # Convert perc_diff_data to array for table\n",
        "#     table_data = display_data.to_numpy()\n",
        "#     # Add table at the right\n",
        "#     table = ax4.table(cellText=table_data, colLabels=display_data.columns, loc='right')\n",
        "#     table.auto_set_font_size(False)\n",
        "#     table.set_fontsize(8.5)  # Set smaller font size if necessary\n",
        "#     table.scale(4, 1.8)  # Adjust scale to fit\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# # data2use = ts2fix\n",
        "# # data2use = tsnonspend\n",
        "# data2use = data2plot\n",
        "# # data2use = rev_at_hier2plot\n",
        "\n",
        "# substring1 = 'romos'\n",
        "# substring2 = 'romos'\n",
        "\n",
        "# # Update data2use to include rows where 'unique_id' contains either substring1 or substring2\n",
        "# # data2use = data2use[data2use['unique_id'].str.contains(substring1 + '|' + substring2, case=False, na=False)]\n",
        "\n",
        "# # data2use = data2use[data2use['unique_id'].str.contains(substring1, case=False, na=False) &\n",
        "# #                     data2use['unique_id'].str.contains(substring2, case=False, na=False)]\n",
        "\n",
        "\n",
        "\n",
        "# # Create widgets\n",
        "# unique_id_selector = widgets.SelectionSlider(\n",
        "#     options=data2use['unique_id'].unique(),\n",
        "#     description='unique_id:',\n",
        "#     orientation='horizontal',\n",
        "#     readout=True\n",
        "# )\n",
        "\n",
        "# # Display interactive plot\n",
        "# interact(plot_data, unique_id=unique_id_selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v5wmhWTp7TPR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kt1hU_3qSilD"
      },
      "outputs": [],
      "source": [
        "# REFERENCE FOR SYNTAX\n",
        "\n",
        "# unrestricted_model_mira_gb = {\n",
        "#     'irregular': False, 'autoregressive': None,\n",
        "#     'level': True, 'stochastic_level': True,\n",
        "#     'trend': True, 'stochastic_trend': False,\n",
        "#     'cycle': True, 'damped_cycle': False, 'stochastic_cycle': False,\n",
        "#     'seasonal': None, 'stochastic_seasonal': True,\n",
        "#     'freq_seasonal':[{'period': 12,'harmonics': 50}]\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST RUNS"
      ],
      "metadata": {
        "id": "6Lrwh94cS8Nk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "yOzvvfz54bo5"
      },
      "outputs": [],
      "source": [
        "# ENZA - Enzalutamide\n",
        "# D_E_AUSTRIA - Austria\n",
        "\n",
        "product2test = 'RAMOS_IRR - RAMOS_IRR'\n",
        "lv52test = 'JP10 - Astellas Pharma Inc'\n",
        "\n",
        "unrestricted_model = {\n",
        "    'irregular': True, 'autoregressive': None,\n",
        "    'level': True, 'stochastic_level': True,\n",
        "    'trend': True, 'stochastic_trend': True,\n",
        "    'cycle': True, 'damped_cycle': False, 'stochastic_cycle': True,\n",
        "    'seasonal': 12, 'stochastic_seasonal': True\n",
        "}\n",
        "\n",
        "id2test = volume_act[(volume_act['ProductLv']==product2test) & (volume_act['Lv5']==lv52test)]['unique_id'].unique()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2XbJ6w8x7cAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb43b26-dde6-4458-883d-c84ba3d3ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Unobserved Components Results                            \n",
            "=====================================================================================\n",
            "Dep. Variable:                             y   No. Observations:                  105\n",
            "Model:                    local linear trend   Log Likelihood               -1725.704\n",
            "                   + stochastic seasonal(12)   AIC                           3463.408\n",
            "                          + stochastic cycle   BIC                           3478.407\n",
            "Date:                       Tue, 30 Apr 2024   HQIC                          3469.456\n",
            "Time:                               18:35:48                                         \n",
            "Sample:                           04-01-2014                                         \n",
            "                                - 12-01-2022                                         \n",
            "Covariance Type:                         opg                                         \n",
            "====================================================================================\n",
            "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "sigma2.irregular  6.814e+14    7.9e-18   8.63e+31      0.000    6.81e+14    6.81e+14\n",
            "sigma2.level       106.3461   3.46e-18   3.07e+19      0.000     106.346     106.346\n",
            "sigma2.trend      2.758e+11   3.63e-16    7.6e+26      0.000    2.76e+11    2.76e+11\n",
            "sigma2.seasonal   5.112e+13    2.2e-17   2.32e+30      0.000    5.11e+13    5.11e+13\n",
            "sigma2.cycle      8.707e+14   4.09e-18   2.13e+32      0.000    8.71e+14    8.71e+14\n",
            "frequency.cycle      0.0436      0.014      3.083      0.002       0.016       0.071\n",
            "===================================================================================\n",
            "Ljung-Box (L1) (Q):                   0.04   Jarque-Bera (JB):             24392.99\n",
            "Prob(Q):                              0.84   Prob(JB):                         0.00\n",
            "Heteroskedasticity (H):                inf   Skew:                             8.79\n",
            "Prob(H) (two-sided):                  0.00   Kurtosis:                        81.71\n",
            "===================================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
            "[2] Covariance matrix is singular or near-singular, with condition number 1.96e+47. Standard errors may be unstable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/stattools.py:1420: RuntimeWarning: divide by zero encountered in divide\n",
            "  test_statistic = numer_squared_sum / denom_squared_sum\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "ssm_data = volume_act.copy()\n",
        "ssm_data = ssm_data[ssm_data['unique_id']==id2test]\n",
        "\n",
        "ssm_data = ssm_data[['ds', 'y']]\n",
        "ssm_data = ssm_data.set_index('ds')\n",
        "\n",
        "# Set train and test period\n",
        "ssm_test = ssm_data.tail(fct_periods)\n",
        "ssm_train = ssm_data.drop(ssm_test.index)\n",
        "ssm_data.index = pd.DatetimeIndex(ssm_data.index.values, freq=ssm_data.index.inferred_freq)\n",
        "\n",
        "# Setup the model\n",
        "# mod = LocalLinearTrend(ssm_train['y'])\n",
        "# res = mod.fit(disp=False)\n",
        "\n",
        "# mod = SeasonalLocalLinearTrend(ssm_train['y'], 12)\n",
        "# res = mod.fit(disp=False)\n",
        "\n",
        "mod = sm.tsa.UnobservedComponents(ssm_train['y'], **unrestricted_model)\n",
        "res = mod.fit(method='powell', disp=False)\n",
        "\n",
        "print(res.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "RLZcK4HCUdCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b9bb84-c998-45dd-ac60-7d7b8be02f2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.84694904405062"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Perform prediction and forecasting\n",
        "predict = res.get_prediction()\n",
        "forecast = res.get_forecast('2024-03-01')\n",
        "\n",
        "actuals_fy23 = ssm_test.loc[ssm_test.index >= fct_st_date]['y'].sum()\n",
        "forecast_fy23 = forecast.predicted_mean.loc[forecast.predicted_mean.index >= fct_st_date].sum()\n",
        "\n",
        "error = ((forecast_fy23-actuals_fy23)/actuals_fy23)*100\n",
        "error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pbSiC4wW7rwz"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "\n",
        "# Plot the results\n",
        "ssm_train['y'].plot(ax=ax, style='k.', label='Train')\n",
        "ssm_test['y'].plot(ax=ax, style='b.', label='Test')\n",
        "predict.predicted_mean.plot(ax=ax, label='One-step-ahead Prediction')\n",
        "predict_ci = predict.conf_int(alpha=0.05)\n",
        "predict_index = np.arange(len(predict_ci))\n",
        "ax.fill_between(predict_index[2:], predict_ci.iloc[2:, 0], predict_ci.iloc[2:, 1], alpha=0.1)\n",
        "\n",
        "forecast.predicted_mean.plot(ax=ax, style='r', label='Forecast')\n",
        "forecast_ci = forecast.conf_int()\n",
        "forecast_index = np.arange(len(predict_ci), len(predict_ci) + len(forecast_ci))\n",
        "ax.fill_between(forecast_index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], alpha=0.1)\n",
        "\n",
        "# Cleanup the image\n",
        "legend = ax.legend(loc='lower left');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eO2vhwEE48OV"
      },
      "outputs": [],
      "source": [
        "fig = res.plot_components(legend_loc='lower right', figsize=(15, 9));"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BULK RUN"
      ],
      "metadata": {
        "id": "BfYbv3tRS0Nz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2YhV1ZZ2Gi32"
      },
      "outputs": [],
      "source": [
        "def forecast_error(df, volume_act, fct_periods, fct_st_date):\n",
        "    # Initialize the output DataFrame\n",
        "    results = pd.DataFrame(columns=['id2test', 'Product', 'Lv5', 'actuals_fy23', 'forecast_fy23', 'error'])\n",
        "\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for idx, row in df.iterrows():\n",
        "        product = row['Product']\n",
        "        Lv5 = row['Lv5']\n",
        "        model_settings = row.drop(['Product', 'Lv5']).to_dict()\n",
        "        print(product)\n",
        "        print(Lv5)\n",
        "        # Determine unique ID based on product and Lv5\n",
        "        id2test = volume_act[(volume_act['ProductLv'] == product) & (volume_act['Lv5'] == Lv5)]['unique_id'].unique()[0]\n",
        "\n",
        "        # Filter the data for this specific ID\n",
        "        ssm_data = volume_act[volume_act['unique_id'] == id2test]\n",
        "        ssm_data = ssm_data[['ds', 'y']]\n",
        "        ssm_data = ssm_data.set_index('ds')\n",
        "        ssm_data.index = pd.DatetimeIndex(ssm_data.index.values, freq=ssm_data.index.inferred_freq)\n",
        "\n",
        "        # Set train and test period\n",
        "        ssm_test = ssm_data.tail(fct_periods)\n",
        "        ssm_train = ssm_data.drop(ssm_test.index)\n",
        "\n",
        "        # Fit the model\n",
        "        mod = sm.tsa.UnobservedComponents(ssm_train['y'], **model_settings)\n",
        "        res = mod.fit(method='powell', disp=False)\n",
        "\n",
        "        # Perform prediction and forecasting\n",
        "        predict = res.get_prediction()\n",
        "        forecast = res.get_forecast('2024-03-01')\n",
        "\n",
        "        actuals_fy23 = ssm_test.loc[ssm_test.index >= fct_st_date]['y'].sum()\n",
        "        forecast_fy23 = forecast.predicted_mean.loc[forecast.predicted_mean.index >= fct_st_date].sum()\n",
        "\n",
        "        error = ((forecast_fy23 - actuals_fy23) / actuals_fy23) * 100\n",
        "\n",
        "        new_row = pd.DataFrame({\n",
        "            'id2test': [id2test],\n",
        "            'Product': [product],\n",
        "            'Lv5': [Lv5],\n",
        "            'actuals_fy23': [actuals_fy23],\n",
        "            'forecast_fy23': [forecast_fy23],\n",
        "            'error': [error]\n",
        "        })\n",
        "\n",
        "        # Using concat to append the new row\n",
        "        results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputFile = '/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/data/unrestricted_model_settings.csv'\n",
        "unrestricted_model_settings = pd.read_csv(inputFile, dtype={'autoregressive': 'Int64'})\n",
        "\n",
        "unrestricted_model_settings = unrestricted_model_settings[(unrestricted_model_settings['LostinOrig']==1) & (unrestricted_model_settings['Success']!=1)]\n",
        "\n",
        "unrestricted_model_settings = unrestricted_model_settings.drop(['Success', 'LostinOrig', '%ofSales'], axis=1)"
      ],
      "metadata": {
        "id": "VUgfaCOIImTn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "rVQGa1Mqlezc",
        "outputId": "430481a9-a799-4ddf-cf3b-9cbd98aa293c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TAMSULOSIN - Tamsulosin HCl\n",
            "D_CN_TOTAL - China Total\n",
            "ENZA - Enzalutamide\n",
            "D_E_NETHLND - Netherlands\n",
            "RAMOS_IRR - RAMOS_IRR\n",
            "JP10 - Astellas Pharma Inc\n",
            "ENZA - Enzalutamide\n",
            "D_E_AUSTRIA - Austria\n",
            "GILTERITNB - Gilteritinib\n",
            "JP10 - Astellas Pharma Inc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  winner                         Lv5                      Product  \\\n",
              "0    Bud    D_CN_TOTAL - China Total  TAMSULOSIN - Tamsulosin HCl   \n",
              "1     Dx   D_E_NETHLND - Netherlands          ENZA - Enzalutamide   \n",
              "2    Bud  JP10 - Astellas Pharma Inc        RAMOS_IRR - RAMOS_IRR   \n",
              "3    Bud       D_E_AUSTRIA - Austria          ENZA - Enzalutamide   \n",
              "4     Dx  JP10 - Astellas Pharma Inc    GILTERITNB - Gilteritinib   \n",
              "\n",
              "      actuals_fy23    forecast_fy23      budget_fy23  error  bud_error  \\\n",
              "0 5,365,808,152.11 4,330,009,380.64 5,761,845,074.72 -19.30       7.38   \n",
              "1 4,560,939,299.00 4,434,274,269.09 4,855,726,495.40  -2.78       6.46   \n",
              "2 4,557,380,370.00 6,874,669,244.48 4,586,302,025.91  50.85       0.63   \n",
              "3 4,537,663,465.77 4,905,800,321.70 4,566,816,959.08   8.11       0.64   \n",
              "4 4,362,018,079.00 4,493,883,838.07 4,113,855,994.77   3.02      -5.69   \n",
              "\n",
              "                                             id2test  \n",
              "0  Global/TAMSULOSIN - Tamsulosin HCl/D_GCN - Gre...  \n",
              "1  Global/ENZA - Enzalutamide/D_E_ESTMKT - Establ...  \n",
              "2  Global/RAMOS_IRR - RAMOS_IRR/D_JPCOM - Japan C...  \n",
              "3  Global/ENZA - Enzalutamide/D_E_ESTMKT - Establ...  \n",
              "4  Global/GILTERITNB - Gilteritinib/D_JPCOM - Jap...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d7885ba-e888-4fee-ada1-25d2b5f51d5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>Lv5</th>\n",
              "      <th>Product</th>\n",
              "      <th>actuals_fy23</th>\n",
              "      <th>forecast_fy23</th>\n",
              "      <th>budget_fy23</th>\n",
              "      <th>error</th>\n",
              "      <th>bud_error</th>\n",
              "      <th>id2test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bud</td>\n",
              "      <td>D_CN_TOTAL - China Total</td>\n",
              "      <td>TAMSULOSIN - Tamsulosin HCl</td>\n",
              "      <td>5,365,808,152.11</td>\n",
              "      <td>4,330,009,380.64</td>\n",
              "      <td>5,761,845,074.72</td>\n",
              "      <td>-19.30</td>\n",
              "      <td>7.38</td>\n",
              "      <td>Global/TAMSULOSIN - Tamsulosin HCl/D_GCN - Gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dx</td>\n",
              "      <td>D_E_NETHLND - Netherlands</td>\n",
              "      <td>ENZA - Enzalutamide</td>\n",
              "      <td>4,560,939,299.00</td>\n",
              "      <td>4,434,274,269.09</td>\n",
              "      <td>4,855,726,495.40</td>\n",
              "      <td>-2.78</td>\n",
              "      <td>6.46</td>\n",
              "      <td>Global/ENZA - Enzalutamide/D_E_ESTMKT - Establ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bud</td>\n",
              "      <td>JP10 - Astellas Pharma Inc</td>\n",
              "      <td>RAMOS_IRR - RAMOS_IRR</td>\n",
              "      <td>4,557,380,370.00</td>\n",
              "      <td>6,874,669,244.48</td>\n",
              "      <td>4,586,302,025.91</td>\n",
              "      <td>50.85</td>\n",
              "      <td>0.63</td>\n",
              "      <td>Global/RAMOS_IRR - RAMOS_IRR/D_JPCOM - Japan C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bud</td>\n",
              "      <td>D_E_AUSTRIA - Austria</td>\n",
              "      <td>ENZA - Enzalutamide</td>\n",
              "      <td>4,537,663,465.77</td>\n",
              "      <td>4,905,800,321.70</td>\n",
              "      <td>4,566,816,959.08</td>\n",
              "      <td>8.11</td>\n",
              "      <td>0.64</td>\n",
              "      <td>Global/ENZA - Enzalutamide/D_E_ESTMKT - Establ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dx</td>\n",
              "      <td>JP10 - Astellas Pharma Inc</td>\n",
              "      <td>GILTERITNB - Gilteritinib</td>\n",
              "      <td>4,362,018,079.00</td>\n",
              "      <td>4,493,883,838.07</td>\n",
              "      <td>4,113,855,994.77</td>\n",
              "      <td>3.02</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>Global/GILTERITNB - Gilteritinib/D_JPCOM - Jap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d7885ba-e888-4fee-ada1-25d2b5f51d5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d7885ba-e888-4fee-ada1-25d2b5f51d5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d7885ba-e888-4fee-ada1-25d2b5f51d5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2985eb44-1c6e-4d91-9f3b-b1fae2505a84\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2985eb44-1c6e-4d91-9f3b-b1fae2505a84')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2985eb44-1c6e-4d91-9f3b-b1fae2505a84 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bcb91078-69d7-43dc-bb81-24cd7fe6d5c4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results2comp')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bcb91078-69d7-43dc-bb81-24cd7fe6d5c4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results2comp');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results2comp",
              "summary": "{\n  \"name\": \"results2comp\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"winner\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Dx\",\n          \"Bud\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lv5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"D_E_NETHLND - Netherlands\",\n          \"D_E_AUSTRIA - Austria\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ENZA - Enzalutamide\",\n          \"GILTERITNB - Gilteritinib\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actuals_fy23\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 393974494.5456533,\n        \"min\": 4362018079.0,\n        \"max\": 5365808152.105293,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4560939299.001661,\n          4362018079.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"forecast_fy23\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1066307459.5547028,\n        \"min\": 4330009380.639089,\n        \"max\": 6874669244.477466,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4434274269.085134,\n          4493883838.073673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"budget_fy23\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 611641283.9325032,\n        \"min\": 4113855994.771765,\n        \"max\": 5761845074.722952,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4855726495.400793,\n          4113855994.771765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.087739604131098,\n        \"min\": -19.303686268764668,\n        \"max\": 50.84694904405062,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -2.7771698243002994,\n          3.023044762434907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bud_error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.282974879271867,\n        \"min\": -5.689157626901133,\n        \"max\": 7.380750697586386,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.4633001466092175,\n          -5.689157626901133\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id2test\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Global/ENZA - Enzalutamide/D_E_ESTMKT - Established Markets/D_E_MSM - Mid Size Markets/D_E_BENELUX - Benelux/D_E_NETHLND - Netherlands/D_E_NETHLND - Netherlands\",\n          \"Global/GILTERITNB - Gilteritinib/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/D_JPCOM - Japan Commercial/JP10 - Astellas Pharma Inc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Assuming 'budget' is your DataFrame\n",
        "grouped_budget = budget.groupby(['unique_id'])['y'].sum().reset_index()\n",
        "grouped_budget.columns=['id2test', 'budget_fy23']\n",
        "\n",
        "# Calculate the number of chunks\n",
        "num_rows = len(unrestricted_model_settings)\n",
        "chunk_size = 5  # Process 5 rows at a time\n",
        "num_chunks = (num_rows // chunk_size) + (1 if num_rows % chunk_size else 0)\n",
        "\n",
        "start_chunk = 3\n",
        "num_chunks = 3\n",
        "\n",
        "# Loop through each chunk\n",
        "for i in range(start_chunk - 1, num_chunks):\n",
        "    start_index = i * chunk_size\n",
        "    end_index = start_index + chunk_size\n",
        "\n",
        "    # Get the subset of the DataFrame\n",
        "    subset = unrestricted_model_settings.iloc[start_index:end_index]\n",
        "\n",
        "    # Check if the subset is empty (this might occur if your total rows are exactly divisible by the chunk size)\n",
        "    if subset.empty:\n",
        "        break\n",
        "\n",
        "    # Run the function\n",
        "    results_df = forecast_error(subset, volume_act, fct_periods, fct_st_date)\n",
        "\n",
        "    # Display the grouped and summed DataFrame\n",
        "    results2comp = results_df.merge(grouped_budget, how='left', on='id2test')\n",
        "    results2comp['bud_error'] = ((results2comp['budget_fy23'] - results2comp['actuals_fy23']) / results2comp['actuals_fy23']) * 100\n",
        "    results2comp['winner'] = np.where(np.abs(results2comp['error']) < np.abs(results2comp['bud_error']), 'Dx', 'Bud')\n",
        "    results2comp = results2comp[['winner','Lv5', 'Product', 'actuals_fy23', 'forecast_fy23', 'budget_fy23', 'error', 'bud_error', 'id2test']]\n",
        "\n",
        "    # # Save the output to a CSV file, naming them uniquely\n",
        "    # results2comp.to_csv(f'/content/drive/MyDrive/Colab Notebooks/Revenue Prediction/results/Blind Test FY23/results_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "results2comp"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XZ_M6G7HRKveiQEP3hBb0gwPipnydfEq",
      "authorship_tag": "ABX9TyMO0c081ZygMxt9w/eJrqyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}